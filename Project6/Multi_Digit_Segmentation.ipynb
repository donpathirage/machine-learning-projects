{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import sklearn\n",
    "import sklearn.preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "\n",
    "mnist_labels = np.load(\"segmented.npy\")\n",
    "_, HEIGHT, WIDTH, N_CLASSES = mnist_labels.shape\n",
    "mnist_inputs = np.load(\"combined.npy\").reshape((-1, HEIGHT, WIDTH, 1))/255\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist_inputs = mnist_inputs.reshape(5000,64,84)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Buster\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py:98: MatplotlibDeprecationWarning: \n",
      "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \"Adding an axes using the same arguments as a previous axes \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kernel = np.ones((2,2),np.uint8)\n",
    "for x in mnist_inputs:\n",
    "    plt.subplot(121),plt.imshow(x.reshape(64,84),cmap = 'gray')\n",
    "    plt.title('Original Image'), plt.xticks([]), plt.yticks([])\n",
    "    x = cv2.dilate(np.round(x.reshape(64,84)).astype('uint8'),kernel,iterations = 1)\n",
    "    mnist_inputs = np.append(mnist_inputs,x.reshape(1,64,84,1),axis=0)\n",
    "    plt.subplot(122),plt.imshow(x,cmap = 'gray')\n",
    "    plt.title('Edge Image'), plt.xticks([]), plt.yticks([])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Buster\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 64, 84, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 64, 96, 1)    0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 64, 96, 32)   832         zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 64, 96, 32)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 64, 96, 32)   25632       leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 32, 48, 32)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 32, 48, 32)   0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 48, 32)   128         leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 48, 64)   51264       batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 32, 48, 64)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 48, 64)   102464      leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 16, 24, 64)   0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 16, 24, 64)   0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 16, 24, 64)   256         leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 16, 24, 128)  204928      batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 16, 24, 128)  0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 16, 24, 128)  409728      leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 8, 12, 128)   0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 8, 12, 128)   0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 8, 12, 128)   512         leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 8, 12, 128)   147584      batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 8, 12, 128)   0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 8, 12, 128)   147584      leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 4, 6, 128)    0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 4, 6, 128)    0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 4, 6, 128)    512         leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 4, 6, 128)    147584      batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 4, 6, 128)    0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 4, 6, 128)    147584      leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 2, 3, 128)    0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 2, 3, 128)    0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 2, 3, 128)    512         leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 2, 3, 128)    147584      batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, 2, 3, 128)    0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 2, 3, 128)    512         leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 2, 3, 128)    147584      batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)      (None, 2, 3, 128)    0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 2, 3, 128)    512         leaky_re_lu_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 4, 6, 128)    409728      batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 4, 6, 256)    0           batch_normalization_4[0][0]      \n",
      "                                                                 conv2d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)      (None, 4, 6, 256)    0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 4, 6, 256)    1024        leaky_re_lu_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 8, 12, 128)   819328      batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 8, 12, 256)   0           batch_normalization_3[0][0]      \n",
      "                                                                 conv2d_transpose_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)      (None, 8, 12, 256)   0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 8, 12, 256)   1024        leaky_re_lu_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 16, 24, 64)   409664      batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 16, 24, 128)  0           batch_normalization_2[0][0]      \n",
      "                                                                 conv2d_transpose_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)      (None, 16, 24, 128)  0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 24, 128)  512         leaky_re_lu_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 32, 48, 64)   204864      batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 32, 48, 96)   0           batch_normalization_1[0][0]      \n",
      "                                                                 conv2d_transpose_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)      (None, 32, 48, 96)   0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 32, 48, 96)   384         leaky_re_lu_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTrans (None, 64, 96, 11)   26411       batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)      (None, 64, 96, 11)   0           conv2d_transpose_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 64, 96, 11)   44          leaky_re_lu_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTrans (None, 64, 96, 11)   3036        batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_1 (Cropping2D)       (None, 64, 84, 11)   0           conv2d_transpose_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 64, 84, 11)   0           cropping2d_1[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 3,559,315\n",
      "Trainable params: 3,556,349\n",
      "Non-trainable params: 2,966\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs=keras.layers.Input((HEIGHT, WIDTH,1))\n",
    "\n",
    "x=keras.layers.ZeroPadding2D(((0, 0), (0, 96-WIDTH)))(inputs)\n",
    "\n",
    "layers = []\n",
    "\n",
    "for n, k, s in [(32, 5, 1),(64, 5, 1),(128, 5, 1),(128, 3, 1),(128, 3, 1)]:\n",
    "    x=keras.layers.Conv2D(n, kernel_size=k, strides=s, padding='same')(x)\n",
    "    x=keras.layers.LeakyReLU()(x)\n",
    "    x=keras.layers.Conv2D(n, kernel_size=k, strides=s, padding='same')(x)\n",
    "    x=keras.layers.MaxPooling2D(pool_size=3, strides=2, padding='same')(x)\n",
    "    x=keras.layers.LeakyReLU()(x)\n",
    "    x=keras.layers.BatchNormalization()(x)\n",
    "    layers.append(x)\n",
    "layers.pop()\n",
    "\n",
    "for n, k, s in [(128, 3, 1),(128, 3, 1)]:\n",
    "    x=keras.layers.Conv2D(n, kernel_size=k, strides=s, padding='same')(x)\n",
    "    x=keras.layers.LeakyReLU()(x)\n",
    "    x=keras.layers.BatchNormalization()(x)\n",
    "    \n",
    "for n, k, s in reversed([(N_CLASSES, 5, 2),(64, 5, 2),(64, 5, 2),(128, 5, 2),(128, 5, 2)]):\n",
    "    x=keras.layers.Conv2DTranspose(n, kernel_size=k, strides=s, padding='same')(x)\n",
    "    if len(layers)>0:\n",
    "        l = layers.pop()\n",
    "        x=keras.layers.concatenate([l, x])\n",
    "    x=keras.layers.LeakyReLU()(x)\n",
    "    x=keras.layers.BatchNormalization()(x)\n",
    "    \n",
    "x=keras.layers.Conv2DTranspose(N_CLASSES, kernel_size=5, strides=1, padding='same')(x)\n",
    "x=keras.layers.Cropping2D(((0, 0), (0, 96-WIDTH)))(x)\n",
    "outputs = keras.layers.Activation('softmax')(x)\n",
    "\n",
    "model = keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = keras.preprocessing.image.ImageDataGenerator(rotation_range=10.0,\n",
    "                                                       width_shift_range=2,\n",
    "                                                       height_shift_range=2,\n",
    "                                                       shear_range=0.0,\n",
    "                                                       zoom_range=0.1,\n",
    "                                                       data_format='channels_last',\n",
    "                                                       validation_split=0.1\n",
    "                                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(loss='categorical_crossentropy',\n",
    "#               optimizer=keras.optimizers.Adam(0.001),\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# epochs = 30\n",
    "# batch_size = 25\n",
    "# model_name = input(\"Specify a name for the model to be saved: \")\n",
    "# model.fit_generator(zip(datagen.flow(mnist_inputs, batch_size=batch_size, subset='training', seed=1), datagen.flow(mnist_labels, batch_size=batch_size, subset='training', seed=1)),\n",
    "#                     epochs=epochs, \n",
    "#                     steps_per_epoch = len(mnist_inputs)//batch_size,\n",
    "#                     validation_data=zip(datagen.flow(mnist_inputs, batch_size=batch_size, subset='validation', seed=1), datagen.flow(mnist_labels, batch_size=batch_size, subset='validation', seed=1)),\n",
    "#                     validation_steps=50,\n",
    "#                     #callbacks=[keras.callbacks.EarlyStopping(monitor='val_acc', min_delta=0, patience=2, verbose=0, mode='auto')],\n",
    "#                     verbose=2\n",
    "#          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('mnist_segmentation.model')   #Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TEST = 1\n",
    "SEED = np.random.randint(0, 1000)\n",
    "originals = next(datagen.flow(mnist_inputs, batch_size=N_TEST, subset='validation', seed=SEED))\n",
    "ground_truth = next(datagen.flow(mnist_labels, batch_size=N_TEST, subset='validation', seed=SEED))\n",
    "predicted = model.predict_on_batch(originals)\n",
    "predicted = np.round(predicted).astype(np.int)\n",
    "plt.figure(figsize=(20, 5))\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "for i in range(N_TEST):\n",
    "    plt.subplot(4, N_TEST, i+1)\n",
    "    plt.imshow(originals[i].reshape((HEIGHT, WIDTH)))\n",
    "    plt.subplot(4, N_TEST, i+1+N_TEST)\n",
    "    plt.imshow(np.argmax(predicted[i], axis=2), vmax=10, vmin=0)\n",
    "    plt.subplot(4, N_TEST, i+1+2*N_TEST)\n",
    "    plt.imshow(np.argmax(ground_truth[i], axis=2), vmax=10, vmin=0)\n",
    "    plt.subplot(4, N_TEST, i+1+3*N_TEST)\n",
    "    plt.imshow(np.any(predicted[i]-ground_truth[i], axis=2))\n",
    "    for j in range(10):\n",
    "        if (predicted[:,:,:,j].sum(1).sum() >= 50):\n",
    "            print(\"Detected a: \" + str(j))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(mnist_inputs[1].reshape(64,84))\n",
    "plt.figure()\n",
    "plt.imshow(np.round(mnist_inputs[1].reshape(64,84)).astype('uint8'), cmap='gray')\n",
    "kernel = np.ones((2,2),np.uint8)\n",
    "dilation = cv2.dilate(np.round(mnist_inputs[1].reshape(64,84)).astype('uint8'),kernel,iterations = 1)\n",
    "plt.figure()\n",
    "plt.imshow(dilation, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(originals[0],axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted[:,:,:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted[:,:,:,j].sum(1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    for j in range(10):\n",
    "        if (predicted[:,:,:,j].sum(1).sum() >= 30):\n",
    "            print(\"Detected a: \" + str(j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1612bb7c630>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mnist_inputs[9990].reshape(64,84),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
