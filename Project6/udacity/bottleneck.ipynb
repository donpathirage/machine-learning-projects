{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('combined.npy') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = (X.astype(np.float32)-127)/127.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.core.framework import graph_pb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_def = graph_pb2.GraphDef()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph(path_protobuf):\n",
    "    with open(path_protobuf, \"rb\") as f:\n",
    "        graph_def.ParseFromString(f.read())\n",
    "        with tf.Graph().as_default() as graph:\n",
    "            # Createa new placeholder\n",
    "            input_big = tf.placeholder(dtype=tf.float32, shape=(None, 64,84,1), name='input_image_big')\n",
    "            # Import the graph and replace the reshape node with new placeholder.\n",
    "            tf.import_graph_def(graph_def, name=\"\", input_map={\"reshaped_image\": input_big})\n",
    "            return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "frozen_graph = load_graph('./checkpoints/frozen_graph.pb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_image_big\n",
      "input_image\n",
      "reshaped_image/shape\n",
      "reshaped_image\n",
      "conv1/kernel\n",
      "conv1/kernel/read\n",
      "conv1/bias\n",
      "conv1/bias/read\n",
      "conv1/Conv2D\n",
      "conv1/BiasAdd\n",
      "conv1/Relu\n",
      "pool1/MaxPool\n",
      "conv2/kernel\n",
      "conv2/kernel/read\n",
      "conv2/bias\n",
      "conv2/bias/read\n",
      "conv2/Conv2D\n",
      "conv2/BiasAdd\n",
      "conv2/Relu\n",
      "poool2/MaxPool\n",
      "flatten/Shape\n",
      "flatten/strided_slice/stack\n",
      "flatten/strided_slice/stack_1\n",
      "flatten/strided_slice/stack_2\n",
      "flatten/strided_slice\n",
      "flatten/Reshape/shape/1\n",
      "flatten/Reshape/shape\n",
      "flatten/Reshape\n",
      "dense32/kernel\n",
      "dense32/kernel/read\n",
      "dense32/bias\n",
      "dense32/bias/read\n",
      "dense32/MatMul\n",
      "dense32/BiasAdd\n",
      "dense32/Relu\n",
      "dense10/kernel\n",
      "dense10/kernel/read\n",
      "dense10/bias\n",
      "dense10/bias/read\n",
      "dense10/MatMul\n",
      "dense10/BiasAdd\n",
      "predictions\n"
     ]
    }
   ],
   "source": [
    "## Uncomment to view all names of all nodes.\n",
    "for op in frozen_graph.get_operations():\n",
    "   print(op.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_batch(X,batch_sz):\n",
    "    for start_offset in range(0, len(X), batch_sz):\n",
    "        end_offfset = min(start_offset+batch_sz, len(X))\n",
    "        yield X[start_offset:end_offfset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottleneck_features = []\n",
    "with tf.Session(graph=frozen_graph) as sess:\n",
    "    # Get placeholder and output tensors of last pooling layer.\n",
    "    # Tensor names are derived from the operation that produced them\n",
    "    # We named layers while building the graph, NOT tensors.\n",
    "    input_ph = tf.get_default_graph().get_tensor_by_name('input_image_big:0')\n",
    "    bottleneck_tensor = tf.get_default_graph().get_tensor_by_name('poool2/MaxPool:0')\n",
    "    \n",
    "    # Loop over the whole dataset\n",
    "    for X_batch in get_next_batch(X, 128):\n",
    "        # Add empty dimension to match the dimesnion of the placeholder.\n",
    "        X_batch = np.expand_dims(X_batch,3)\n",
    "        \n",
    "        bottleneck_batch = sess.run(bottleneck_tensor,feed_dict={input_ph:X_batch}) \n",
    "        bottleneck_features.extend(bottleneck_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('bottleneck.npy',bottleneck_features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
